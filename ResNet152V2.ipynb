{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "\n",
    "# from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"C:/Users/abini/Downloads/arch-20230623T040111Z-001/arch/train\"\n",
    "test_dir = \"C:/Users/abini/Downloads/arch-20230623T040111Z-001/arch/test\"\n",
    "\n",
    "SEED = 12\n",
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH = 64\n",
    "BATCH_SIZE = 64      #Was 46\n",
    "EPOCHS = 1\n",
    "LR =  0.1\n",
    "NUM_CLASSES = 14\n",
    "CLASS_LABELS = ['gargoyle','dome(outer)','flying_buttress','altar','dome(inner)','bell_tower','vault','stained_glass','column','apse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_fun = tf.keras.applications.resnet.preprocess_input\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "                                   horizontal_flip=True,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.05,\n",
    "                                   rescale = 1./255,\n",
    "                                   validation_split=0.2, # set validation split, Added\n",
    "                                   preprocessing_function=preprocess_fun\n",
    "                                  )\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  preprocessing_function=preprocess_fun\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7954 images belonging to 10 classes.\n",
      "Found 1984 images belonging to 10 classes.\n",
      "Found 1376 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                    target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle  = True ,\n",
    "                                                    color_mode = \"rgb\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                     subset='training',    #Added\n",
    "                                                    seed = SEED\n",
    "                                                   )\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(train_dir, # same directory as training data\n",
    "                                                    target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle  = True ,\n",
    "                                                    color_mode = \"rgb\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    subset='validation', # set as validation data,  #Added\n",
    "                                                    seed = SEED\n",
    "                                                   )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(directory = test_dir,\n",
    "                                                   target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle  = False ,\n",
    "                                                    color_mode = \"rgb\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    seed = SEED\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath=\"weights-improvementdesnet121-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(inputs):\n",
    "    feature_extractor = tf.keras.applications.ResNet101(input_shape=(IMG_HEIGHT,IMG_WIDTH, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights=\"imagenet\")(inputs)\n",
    "\n",
    "    return feature_extractor\n",
    "\n",
    "def classifier(inputs):\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = tf.keras.layers.dense(256, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.4) (x)\n",
    "    x = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"classification\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def final_model(inputs):\n",
    "    resnet_feature_extractor = feature_extractor(inputs)\n",
    "    classification_output = classifier(resnet_feature_extractor)\n",
    "\n",
    "    return classification_output\n",
    "\n",
    "def define_compile_model():\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=(IMG_HEIGHT ,IMG_WIDTH,3))\n",
    "    classification_output = final_model(inputs)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs = classification_output)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(LR),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = define_compile_model()\n",
    "# clear_output()\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
